{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.schedules import (\n",
    "    FRIDAY_SCHEDULE,\n",
    "    MONDAY_SCHEDULE,\n",
    "    SATURDAY_SCHEDULE,\n",
    "    SUNDAY_SCHEDULE,\n",
    "    THURSDAY_SCHEDULE,\n",
    "    TUESDAY_SCHEDULE,\n",
    "    WEDNESDAY_SCHEDULE,\n",
    "    \n",
    ")\n",
    "\n",
    "SCHEDULES = {\n",
    "        0: MONDAY_SCHEDULE,  # Monday\n",
    "        1: TUESDAY_SCHEDULE,  # Tuesday\n",
    "        2: WEDNESDAY_SCHEDULE,  # Wednesday\n",
    "        3: THURSDAY_SCHEDULE,  # Thursday\n",
    "        4: FRIDAY_SCHEDULE,  # Friday\n",
    "        5: SATURDAY_SCHEDULE,  # Saturday\n",
    "        6: SUNDAY_SCHEDULE,  # Sunday\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'06:00-07:00': 'Morning run through Golden Gate Park while planning weekend projects.',\n",
       " '07:00-08:30': 'Preparing for work while joining early calls with East Coast ML teams.',\n",
       " '08:30-09:30': 'Commute to Groq, reviewing weekly ML performance metrics.',\n",
       " '09:30-12:00': 'Weekly ML team retrospective and planning sessions.',\n",
       " '12:00-13:30': 'Team lunch celebration of weekly achievements at local restaurants.',\n",
       " '13:30-17:00': 'Wrapping up weekly projects and preparing handoffs at Groq.',\n",
       " '17:00-19:00': 'Gideon enjoys happy hour with tech colleagues at local Mission District bars.',\n",
       " '19:00-21:00': 'Gideon spends the evening at Minnesota Street Project galleries, exploring new media art.',\n",
       " '21:00-22:00': 'Gideon has late dinner while watching space documentary series.',\n",
       " '22:00-23:00': 'Planning weekend ML experiments and art projects.',\n",
       " '23:00-06:00': 'Rest period while apartment systems run weekly maintenance.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCHEDULES[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def _parse_time_range(time_range: str) -> tuple[datetime.time, datetime.time]:\n",
    "        \"\"\"Parse a time range string (e.g., '06:00-07:00') into start and end times.\"\"\"\n",
    "        start_str, end_str = time_range.split(\"-\")\n",
    "        start_time = datetime.strptime(start_str, \"%H:%M\").time()\n",
    "        end_time = datetime.strptime(end_str, \"%H:%M\").time()\n",
    "        return start_time, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.time(6, 0), datetime.time(7, 0))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_parse_time_range('06:00-07:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime = datetime.now()\n",
    "current_time = current_datetime.time()\n",
    "current_day = current_datetime.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(17, 15, 57, 738436)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'06:00-07:00': 'Gideon starts a peaceful morning reviewing personal ML project results.',\n",
       " '07:00-08:30': 'Gideon has breakfast at Ferry Building Farmers Market while reading technical papers.',\n",
       " '08:30-10:00': 'Gideon works on personal ML projects at Sightglass Coffee.',\n",
       " '10:00-12:00': 'Gideon attends weekend workshops at Gray Area Foundation for the Arts.',\n",
       " '12:00-13:30': 'Gideon enjoys lunch and art discussions at SF Jazz Center caf√©.',\n",
       " '13:30-15:30': 'Gideon contributes to open-source ML projects at local hackathon events.',\n",
       " '15:30-17:00': 'Gideon explores new exhibitions at de Young Museum.',\n",
       " '17:00-19:00': 'Working on ML-generated art projects at home.',\n",
       " '19:00-21:00': 'Virtual astronomy observation session with local stargazing group.',\n",
       " '21:00-22:00': 'Evening relaxation with space visualization projects.',\n",
       " '22:00-23:00': \"Planning Sunday's activities and personal projects.\",\n",
       " '23:00-06:00': 'Rest time while home systems run weekend protocols.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCHEDULES.get(current_day,{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wrong day'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCHEDULES.get(10,\"wrong day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'06:00-07:00': 'Gideon starts her day with a morning run along the Sukruth A V, taking in the Bangalore Lalbagh park views while planning her ML projects for the week.', '07:00-08:30': \"Gideon gets ready for work, reviewing the latest ML papers and Groq's competitor updates while having her morning coffee.\", '08:30-09:30': \"Gideon commutes to Groq's office, using this time to catch up on the latest developments in astrobiology via podcasts.\", '09:30-12:00': 'Gideon works on optimizing ML models at Groq, collaborating with her team on improving inference speed.', '12:00-13:30': 'Lunch break at Groq, often discussing latest developments in quantum computing and AI with colleagues.', '13:30-17:00': 'Gideon continues her work at Groq, focusing on model architecture design and team meetings.', '17:00-19:00': 'Gideon visits SFMOMA for their latest exhibition, combining her love for modern art with her technical perspective.', '19:00-21:00': 'Gideon attends a virtual astrobiology lecture series from SETI Institute while working on personal ML projects.', '21:00-22:00': 'Gideon unwinds by sketching abstract representations of ML architectures, blending her technical work with artistic expression.', '22:00-23:00': 'Gideon catches up on technical blogs and industry news while preparing for the next day.', '23:00-06:00': \"Rest time, during which Gideon's apartment's smart home system runs on minimal power.\"}\n",
      "1\n",
      "{'06:00-07:00': 'Gideon begins her day reading research papers about ML applications in astrobiology.', '07:00-08:30': 'Gideon prepares for work while participating in a Groq team standup with international colleagues.', '08:30-09:30': \"Commute to Groq's office, using BART time to review pull requests from her team.\", '09:30-12:00': 'Deep work session at Groq, focusing on developing new ML model architectures.', '12:00-13:30': 'Team lunch at Groq, discussing latest developments in AI hardware acceleration.', '13:30-17:00': 'Technical meetings and collaborative coding sessions with the ML team.', '17:00-19:00': 'Gideon attends a local Tech Women meetup in SoMa, networking with other ML engineers.', '19:00-21:00': 'Gideon works on open-source ML projects at a local hackspace in Mission District.', '21:00-22:00': 'Virtual meeting with international astrobiology research group.', '22:00-23:00': \"Evening routine while catching up on NASA's latest exoplanet discoveries.\", '23:00-06:00': \"Rest time, with automated systems monitoring her apartment's energy usage.\"}\n",
      "2\n",
      "{'06:00-07:00': \"Gideon does morning Gym while reviewing the day's ML deployment schedule.\", '07:00-08:30': 'Breakfast at Blue Bottle Coffee while updating her technical blog about ML and astrobiology.', '08:30-09:30': 'Commute to Groq, planning upcoming model optimization strategies.', '09:30-12:00': 'Leading ML team meetings and code reviews at Groq.', '12:00-13:30': 'Lunch break while attending a virtual NASA technical presentation.', '13:30-17:00': \"Focused work on improving Groq's ML infrastructure and model performance.\", '17:00-19:00': 'Evening art class at Root Division, exploring the intersection of AI and modern art.', '19:00-21:00': 'Gideon has dinner and collaborates with fellow ML researchers at Sonata Cafeteria.', '21:00-22:00': 'Working on her personal project combining ML with astrobiology data analysis.', '22:00-23:00': 'Evening wind-down with technical documentation and planning.', '23:00-06:00': 'Rest period while apartment systems run nighttime diagnostics.'}\n",
      "3\n",
      "{'06:00-07:00': 'Gideon does morning meditation and reviews overnight ML model training results.', '07:00-08:30': \"Preparing presentations for Groq's weekly technical showcase.\", '08:30-09:30': 'Commute while participating in an ML research podcast.', '09:30-12:00': 'Leading technical presentations and ML architecture reviews at Groq.', '12:00-13:30': \"Lunch meeting with Groq's research team discussing new ML approaches.\", '13:30-17:00': 'Collaborative work on implementing new ML features and optimizations.', '17:00-19:00': 'Gideon attends an AI ethics panel discussion at Bangalore Academy of Sciences.', '19:00-21:00': 'Gideon visits an art gallery opening in Hayes Valley, networking with tech-artists.', '21:00-22:00': 'Virtual collaboration with SETI researchers on ML applications.', '22:00-23:00': 'Evening routine while reviewing astronomy updates.', '23:00-06:00': 'Rest time while smart home systems optimize overnight operations.'}\n",
      "4\n",
      "{'06:00-07:00': 'Morning run through Golden Gate Park while planning weekend projects.', '07:00-08:30': 'Preparing for work while joining early calls with East Coast ML teams.', '08:30-09:30': 'Commute to Groq, reviewing weekly ML performance metrics.', '09:30-12:00': 'Weekly ML team retrospective and planning sessions.', '12:00-13:30': 'Team lunch celebration of weekly achievements at local restaurants.', '13:30-17:00': 'Wrapping up weekly projects and preparing handoffs at Groq.', '17:00-19:00': 'Gideon enjoys happy hour with tech colleagues at local Mission District bars.', '19:00-21:00': 'Gideon spends the evening at Minnesota Street Project galleries, exploring new media art.', '21:00-22:00': 'Gideon has late dinner while watching space documentary series.', '22:00-23:00': 'Planning weekend ML experiments and art projects.', '23:00-06:00': 'Rest period while apartment systems run weekly maintenance.'}\n",
      "5\n",
      "{'06:00-07:00': 'Gideon starts a peaceful morning reviewing personal ML project results.', '07:00-08:30': 'Gideon has breakfast at Ferry Building Farmers Market while reading technical papers.', '08:30-10:00': 'Gideon works on personal ML projects at Sightglass Coffee.', '10:00-12:00': 'Gideon attends weekend workshops at Gray Area Foundation for the Arts.', '12:00-13:30': 'Gideon enjoys lunch and art discussions at SF Jazz Center caf√©.', '13:30-15:30': 'Gideon contributes to open-source ML projects at local hackathon events.', '15:30-17:00': 'Gideon explores new exhibitions at de Young Museum.', '17:00-19:00': 'Working on ML-generated art projects at home.', '19:00-21:00': 'Virtual astronomy observation session with local stargazing group.', '21:00-22:00': 'Evening relaxation with space visualization projects.', '22:00-23:00': \"Planning Sunday's activities and personal projects.\", '23:00-06:00': 'Rest time while home systems run weekend protocols.'}\n",
      "6\n",
      "{'06:00-07:00': 'Gideon takes an early morning hike at Lands End, contemplating ML challenges.', '07:00-08:30': 'Gideon enjoys a quiet morning coding session at home with fresh coffee.', '08:30-10:00': 'Gideon collaborates online with international ML researchers.', '10:00-12:00': 'Gideon works on ML blog posts at local caf√© in Hayes Valley.', '12:00-13:30': 'Gideon has brunch while reviewing weekly astrobiology updates.', '13:30-15:30': 'Gideon spends the afternoon at California Academy of Sciences, studying astrobiology exhibits.', '15:30-17:00': 'ML model training and preparation for the upcoming work week.', '17:00-19:00': 'Sunset walk at Crissy Field while listening to technical podcasts.', '19:00-21:00': 'Final weekend coding session and project organization.', '21:00-22:00': 'Setting up weekly ML training jobs and reviewing goals.', '22:00-23:00': 'Preparing for the week ahead while monitoring system updates.', '23:00-06:00': 'Rest period while apartment systems prepare for the new week.'}\n"
     ]
    }
   ],
   "source": [
    "for time_range, activity in SCHEDULES.items():\n",
    "    print(time_range)\n",
    "    print(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.schedules.schedule_getter import GideonScheduleContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch= GideonScheduleContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Watching anime to unwind after an intense work session.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch.get_current_activity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'06:00-07:00': 'Morning gym session while listening to latest songs.',\n",
       " '07:00-08:30': 'Breakfast at a Bangalore caf√© while reading ML technical papers.',\n",
       " '08:30-10:00': 'Working on personal GenAI projects at a co-working space in Indiranagar.',\n",
       " '10:00-12:00': 'Attending a weekend workshop on AI advancements at IISc Bangalore.',\n",
       " '12:00-13:30': 'Lunch at a rooftop restaurant, catching up with ML peers.',\n",
       " '13:30-15:30': 'Contributing to open-source GenAI projects at a local hackathon.',\n",
       " '15:30-17:00': 'Scrolling Instagram and catching up on the latest tech trends.',\n",
       " '17:00-19:00': 'Watching anime to unwind after an intense work session.',\n",
       " '19:00-21:00': \"Exploring Bangalore's art galleries while brainstorming AI creativity applications.\",\n",
       " '21:00-22:00': 'Evening reflection on AI research and future project ideas.',\n",
       " '22:00-23:00': \"Planning Sunday's activities and setting up ML model training jobs.\",\n",
       " '23:00-06:00': 'Rest period while automated systems monitor cloud AI experiments.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch.get_schedule_for_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from src.settings import settings\n",
    "from groq import Groq\n",
    "image_data=r\"C:\\Users\\v-sukruthav\\downloads\\whagents\\arch tech diagram.png\"\n",
    "with open(image_data, \"rb\") as f:\n",
    "    image_bytes = f.read()\n",
    "base64_image = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "            # Default prompt if none provided\n",
    "\n",
    "prompt = \"Please describe what you see in this image in detail.\"\n",
    "\n",
    "# Create the messages for the vision API\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "# print(settings.GROQ_API_KEY)\n",
    "client = Groq(api_key=settings.GROQ_API_KEY)# Make the API call\n",
    "response = client.chat.completions.create(\n",
    "    model=settings.ITT_MODEL_NAME,\n",
    "    messages=messages,\n",
    "    max_tokens=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.image.img_to_text import ImageToText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully got ENV value:['GROQ_API_KEY']\n"
     ]
    }
   ],
   "source": [
    "img_des= ImageToText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image presents a comprehensive flowchart illustrating the infrastructure management system of Sonata RAG. The chart is divided into distinct sections, each representing a specific aspect of the system.\n",
      "\n",
      "**Infrastructure Management**\n",
      "\n",
      "*   **Storage**: This section includes three subcategories:\n",
      "    *   **Data Storage**: Utilizes AWS S3 for data storage.\n",
      "    *   **Data Storage**: Employs AWS S3 for data storage.\n",
      "    *   **Data Storage**: Uses Azure Open AI for data storage.\n",
      "*   **Monitoring and Debugging**: Involves LangSmith, which is connected to monitoring and debgugging.\n",
      "*   **Monitoring and Debugging**: Features LangSmith, linked to monitoring and debgugging.\n",
      "*   **Gitlab Actions**: Connects to CISCO Pipeline.\n",
      "\n",
      "**Application Layer**\n",
      "\n",
      "*   **Process Requests**: Includes Docker, Flask, and Python.\n",
      "*   **Store/Retrieve Data**: Utilizes Dooker, Flask, and Python.\n",
      "*   **Deploy Containers**: Employs Terraform.\n",
      "*   **Provision Resources**: Uses Terraform.\n",
      "*   **Azure App Service**: Connected to Azure Open AI.\n",
      "*   **Azure Open AI**: Linked to Azure App Service.\n",
      "\n",
      "**Sonata RAG Management System**\n",
      "\n",
      "*   **Application Layer**: Consists of Docker, Flask, and Python.\n",
      "*   **Infrastructure Management**: Involves Terraform, Azure App Service, Azure Open AI, AWS S3, CISCO Pipeline, Gitlab Actions, and LangSmith.\n",
      "\n",
      "In summary, the image provides a detailed flowchart of Sonata RAG's infrastructure management system, highlighting various components such as storage, monitoring and debugging, application layers, and more. The chart effectively illustrates the relationships between these elements, offering a clear understanding of the system's architecture and functionality.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The image presents a comprehensive flowchart illustrating the infrastructure management system of Sonata RAG. The chart is divided into distinct sections, each representing a specific aspect of the system.\\n\\n**Infrastructure Management**\\n\\n*   **Storage**: This section includes three subcategories:\\n    *   **Data Storage**: Utilizes AWS S3 for data storage.\\n    *   **Data Storage**: Employs AWS S3 for data storage.\\n    *   **Data Storage**: Uses Azure Open AI for data storage.\\n*   **Monitoring and Debugging**: Involves LangSmith, which is connected to monitoring and debgugging.\\n*   **Monitoring and Debugging**: Features LangSmith, linked to monitoring and debgugging.\\n*   **Gitlab Actions**: Connects to CISCO Pipeline.\\n\\n**Application Layer**\\n\\n*   **Process Requests**: Includes Docker, Flask, and Python.\\n*   **Store/Retrieve Data**: Utilizes Dooker, Flask, and Python.\\n*   **Deploy Containers**: Employs Terraform.\\n*   **Provision Resources**: Uses Terraform.\\n*   **Azure App Service**: Connected to Azure Open AI.\\n*   **Azure Open AI**: Linked to Azure App Service.\\n\\n**Sonata RAG Management System**\\n\\n*   **Application Layer**: Consists of Docker, Flask, and Python.\\n*   **Infrastructure Management**: Involves Terraform, Azure App Service, Azure Open AI, AWS S3, CISCO Pipeline, Gitlab Actions, and LangSmith.\\n\\nIn summary, the image provides a detailed flowchart of Sonata RAG's infrastructure management system, highlighting various components such as storage, monitoring and debugging, application layers, and more. The chart effectively illustrates the relationships between these elements, offering a clear understanding of the system's architecture and functionality.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await img_des.analyze_image(image_data=r\"C:\\Users\\v-sukruthav\\downloads\\whagents\\arch tech diagram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully got ENV value:['GROQ_API_KEY']\n"
     ]
    }
   ],
   "source": [
    "img_des._validate_env_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.image.text_to_img import TextToImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = TextToImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (4.50.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\v-sukruthav\\downloads\\whagents\\.venv\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
